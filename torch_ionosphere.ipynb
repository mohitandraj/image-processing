{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e227e5bc-f9c3-40b1-af9b-05b023b0a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc4a355-63f6-47ab-8950-0af80ed80c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_plot_tf_hist(hist_df : pd.DataFrame):\n",
    "    '''\n",
    "    Note this function is specifically designed to plot Tensorflow training output\n",
    "    Args:\n",
    "      hist_df : pandas DataFrame with four columns\n",
    "                For 'x' values, we will use index\n",
    "                first column is accuracy\n",
    "                Second column is loss\n",
    "                third column is val_accuracy\n",
    "                fourth column is val_loss\n",
    "    '''\n",
    "    fig, axes = plt.subplots(1,2 , figsize = (15,6)) # instantiate plot\n",
    "\n",
    "    # properties  matplotlib.patch.Patch \n",
    "    props = dict(boxstyle='round', facecolor='aqua', alpha=0.4)\n",
    "    facecolor = 'cyan'\n",
    "    fontsize=12\n",
    "    \n",
    "    # Get columns by index to eliminate any column naming error\n",
    "    y1 = hist_df.columns[0]\n",
    "    y2 = hist_df.columns[1]\n",
    "    y3 = hist_df.columns[2]\n",
    "    y4 = hist_df.columns[3]\n",
    "\n",
    "    # Where was min loss\n",
    "    best = hist_df[hist_df[y4] == hist_df[y4].min()]\n",
    " \n",
    "    ax = axes[0]\n",
    "\n",
    "    hist_df.plot(y = [y2,y4], ax = ax, colormap=CMAP)\n",
    "\n",
    "\n",
    "    # little beautification\n",
    "    txtFmt = \"Loss: \\n  train: {:6.4f}\\n   test: {:6.4f}\"\n",
    "    txtstr = txtFmt.format(hist_df.iloc[-1][y2],\n",
    "                           hist_df.iloc[-1][y4]) #text to plot\n",
    "    \n",
    "    # place a text box in upper middle in axes coords\n",
    "    ax.text(0.3, 0.95, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    # Mark arrow at lowest\n",
    "    ax.annotate(f'Min: {best[y4].to_numpy()[0]:6.4f}', # text to print\n",
    "                xy=(best.index.to_numpy(), best[y4].to_numpy()[0]), # Arrow start\n",
    "                xytext=(best.index.to_numpy()-1, best[y4].to_numpy()[0]), # location of text \n",
    "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
    "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
    "\n",
    "    # Draw vertical line at best value\n",
    "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
    "\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(y2.capitalize())\n",
    "    ax.set_title('Errors')\n",
    "    ax.legend(loc = 'upper left') # model legend to upper left\n",
    "\n",
    "    ax = axes[1]\n",
    "\n",
    "    hist_df.plot( y = [y1, y3], ax = ax, colormap=CMAP)\n",
    "    \n",
    "    # little beautification\n",
    "    txtFmt = \"Accuracy: \\n  train: {:6.4f}\\n  test:  {:6.4f}\"\n",
    "    txtstr = txtFmt.format(hist_df.iloc[-1][y1],\n",
    "                           hist_df.iloc[-1][y3]) #text to plot\n",
    "\n",
    "    # place a text box in upper middle in axes coords\n",
    "    ax.text(0.3, 0.2, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    # Mark arrow at lowest\n",
    "    ax.annotate(f'Best: {best[y3].to_numpy()[0]:6.4f}', # text to print\n",
    "                xy=(best.index.to_numpy(), best[y3].to_numpy()[0]), # Arrow start\n",
    "                xytext=(best.index.to_numpy()-1, best[y3].to_numpy()[0]), # location of text \n",
    "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
    "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
    "    \n",
    "    \n",
    "    # Draw vertical line at best value\n",
    "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
    "\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(y1.capitalize())\n",
    "    ax.legend(loc = 'lower left')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdb8650-f68c-4b2e-8321-f00e08d1380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "\n",
    "\n",
    "EPOCHS = 100 # number of cycles to run\n",
    "ALPHA = 0.001 # learning rate\n",
    "WEIGHT_DECAY = 0.001\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_SIZE = BATCH_SIZE * 9\n",
    "LR_FACTOR = 0.1\n",
    "LR_PATIENCE= 10\n",
    "\n",
    "# Set parameters for decoration of plots\n",
    "params = {'legend.fontsize' : 'large',\n",
    "          'figure.figsize'  : (9,9),\n",
    "          'axes.labelsize'  : 'x-large',\n",
    "          'axes.titlesize'  :'x-large',\n",
    "          'xtick.labelsize' :'large',\n",
    "          'ytick.labelsize' :'large',\n",
    "         }\n",
    "\n",
    "plt.rcParams.update(params) # update rcParams\n",
    "CMAP = plt.cm.coolwarm\n",
    "plt.style.use('seaborn-v0_8-darkgrid') # plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f858448-1139-4198-800c-67dfa9015fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('ionosphere.data', header = None)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d151e378-aac3-42bc-a99a-ff16bde01a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df.drop(data_df.columns[-1], axis = 1).to_numpy()\n",
    "\n",
    "y = data_df[data_df.columns[-1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091d184a-5b71-43c7-a641-67b734354693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 35), (63, 35))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df= train_test_split(data_df,train_size=TRAIN_SIZE,stratify=data_df[data_df.columns[-1]], random_state=RANDOM_STATE)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12444ad-d74f-4877-9eae-04569354a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe363b55-a79f-4a6f-a1ae-3aae46070332",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' using singleton design pattern'''\n",
    "\n",
    "class Transformers:\n",
    "    _instance = None\n",
    "\n",
    "    def __init__(self):\n",
    "        if Transformers._instance is not None:\n",
    "            raise Exception (\"GlobalScaler class is a singleton.\")\n",
    "\n",
    "        self.scaler  = StandardScaler()\n",
    "        self.encoder = LabelEncoder()\n",
    "\n",
    "    @classmethod\n",
    "    def get_instance(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = Transformers()\n",
    "        return cls._instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "281246be-4e8e-44e8-a10d-065e95367352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this code , we define a custom dataset called FifaDS that takes a Dataframe as input.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In this code , we define a custom dataset called FifaDS that takes a Dataframe as input.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a969bddf-1d2c-4ea2-8d06-392aad5e2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IonoDS(Dataset):\n",
    "    transformers= Transformers.get_instance()\n",
    "    \n",
    "    def __init__(self,\n",
    "                dataframe: pd.DataFrame,\n",
    "                device: str= device,\n",
    "                is_train= True,\n",
    "                label_col= None\n",
    "                ):\n",
    "\n",
    "        super(IonoDS, self).__init__()\n",
    "\n",
    "        self.df= dataframe\n",
    "        self.device= device\n",
    "        self.is_train = is_train\n",
    "        self.encoder = self.transformers.encoder\n",
    "        self.scaler = self.transformers.scaler\n",
    "        self.label_col = label_col\n",
    "\n",
    "        y = self.df[label_col].to_numpy()\n",
    "        X = self.df.drop(label_col, axis = 1)\n",
    "\n",
    "        if self.is_train:\n",
    "            self.labels = self.encoder.fit_transform(y)\n",
    "            self.features = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            self.labels = self.encoder.transform(y)\n",
    "            self.labels = self.encoder.transform(X)\n",
    "    def __len__(self):\n",
    "         return len(self.features)\n",
    "    def __getitem__(self, index):\n",
    "         features = self.features[index]\n",
    "         label = self.labels[index]\n",
    "\n",
    "         features = torch.tensor(features, dtype=torch.float32 , device=self.device)\n",
    "         label = torch.tensor(label, dtype = torch.int64, device = self.device)\n",
    "\n",
    "\n",
    "         return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05785143-de1f-47ff-97a6-bfd42ec5a2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (layer1): Linear(in_features=34, out_features=26, bias=True)\n",
      "  (bm1): BatchNorm1d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (do1): Dropout(p=0.05, inplace=False)\n",
      "  (act1): ReLU()\n",
      "  (layer2): Linear(in_features=26, out_features=18, bias=True)\n",
      "  (bm2): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (do2): Dropout(p=0.15, inplace=False)\n",
      "  (act2): ReLU()\n",
      "  (layer3): Linear(in_features=18, out_features=10, bias=True)\n",
      "  (bm3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (do3): Dropout(p=0.25, inplace=False)\n",
      "  (act3): ReLU()\n",
      "  (layer4): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        dor1 = 0.05\n",
    "        dor2 = 0.15\n",
    "        dor3 = 0.25\n",
    "\n",
    "        self.layer1 = nn.Linear(input_dim, 26)\n",
    "        self.bm1    = nn.BatchNorm1d(26)\n",
    "        self.do1    = nn.Dropout(dor1)\n",
    "        self.act1   = nn.ReLU()\n",
    "\n",
    "        self.layer2 = nn.Linear(26,18)\n",
    "        self.bm2    = nn.BatchNorm1d(18)\n",
    "        self.do2    = nn.Dropout(dor2)\n",
    "        self.act2   = nn.ReLU()\n",
    "\n",
    "        self.layer3 = nn.Linear(18,10)\n",
    "        self.bm3    = nn.BatchNorm1d(10)\n",
    "        self.do3    = nn.Dropout(dor3)\n",
    "        self.act3   = nn.ReLU()\n",
    "\n",
    "        self.layer4  = nn.Linear(10,2)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #activation functions by layer\n",
    "\n",
    "        x = self.do1(self.act1(self.bn1(self.layer1(x))))\n",
    "        x = self.do2(self.act2(self.bn2(self.layer2(x))))\n",
    "        x = self.do3(self.act3(self.bn3(self.layer3(x))))\n",
    "\n",
    "        output = self.softmax(self.layer4(x))\n",
    "\n",
    "        return output\n",
    "\n",
    "input_dim = 34\n",
    "model     = Model(input_dim).to(device)\n",
    "        \n",
    "print(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a0f774f-cec4-4a80-95eb-06a4f9c2537a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (63, 34) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m label_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m34\u001b[39m\n\u001b[0;32m      2\u001b[0m train_ds  \u001b[38;5;241m=\u001b[39m IonoDS(train_df, is_train\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, label_col \u001b[38;5;241m=\u001b[39m label_col)\n\u001b[1;32m----> 3\u001b[0m test_ds   \u001b[38;5;241m=\u001b[39m \u001b[43mIonoDS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m, in \u001b[0;36mIonoDS.__init__\u001b[1;34m(self, dataframe, device, is_train, label_col)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform labels to normalized encoding.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Labels as normalized encodings.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 132\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# transform of empty array is empty array\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1367\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1357\u001b[0m             (\n\u001b[0;32m   1358\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1363\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1364\u001b[0m         )\n\u001b[0;32m   1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1369\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (63, 34) instead."
     ]
    }
   ],
   "source": [
    "label_col = 34\n",
    "train_ds  = IonoDS(train_df, is_train= True, label_col = label_col)\n",
    "test_ds   = IonoDS(test_df,  is_train=False, label_col = label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637ec93-96c4-4488-8d22-bfe695c64bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a050c0-41b3-4eb9-bd3b-5f313c74cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn     = nn.CrossEntropyLoss()\n",
    "\n",
    "loss, tloss = [],[]\n",
    "acc, tacc   = [],[]\n",
    "n_epoch     = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr = ALPHA,\n",
    "                            weight_decay = 0.1e-5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                      mode = 'min',\n",
    "                                                      factor = LR_FACTOR,\n",
    "                                                      patience = LR_PATIENCE,\n",
    "                                                      min_lr= 1e-5)\n",
    "\n",
    "minLoss  = float('inf')\n",
    "\n",
    "savePath = os.path.join(modelDir, subDir, 'iono.pth')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_acc  = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs    = model(inputs)\n",
    "        preds      = torch.argmax(outputs, dim = 1)\n",
    "        batch_loss = loss_fn(outputs, labels)\n",
    "        batch_acc  = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += batch_loss.item() * inputs.size(0)\n",
    "        train_acc  ++ batch_acc * inputs.size(0)\n",
    "\n",
    "    train_loss /= len(train_ds)\n",
    "    train_acc  /= len(train_ds)\n",
    "\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8afdf-e6d7-4de1-b100-a6d8e0c1f0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
